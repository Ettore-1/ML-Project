{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Machine learning project</h1>\n",
    "<hr>\n",
    "<p>This Jupyter notebook resume all our programmation work on binary classification, the Banknote Authentication Dataset and the Kidney Disease Dataset.</p>\n",
    "<p>Students:<br>\n",
    "    <li>Ettoré Hidoux</li>\n",
    "    <li>Agathe Fernandez Machado</li>\n",
    "    <li>Yasmine Diouri</li>\n",
    "    <li>Clément Mathé</li></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries: Standard ones\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random as rnd\n",
    "    # Libraries: scikit learn for preprocessing \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocessing(abcd_csv, clas, lp, sep):\n",
    "    #abcd_csv is data name\n",
    "    #clas is the class namme of the data\n",
    "    #lp is yhe number of a full row \n",
    "    #sep is the symbol use as separator for the data\n",
    "    \n",
    "    # Load the data: data_banknote_authentification\n",
    "    data = pd.read_csv(abcd_csv,sep=sep)\n",
    "    \n",
    "    # X/Y separation\n",
    "    # transform class column from string into boolean if it's necessary\n",
    "    if isinstance(data[clas][lp], str):\n",
    "        Y = np.multiply([data[clas]==data[clas][0]],1)[0]\n",
    "    else:\n",
    "        Y = data[clas]\n",
    "    data.drop(clas, 1, inplace=True)\n",
    "    \n",
    "    #transform data column from string into boolean if it's necessary\n",
    "    for c in data:\n",
    "        if isinstance(data[c][lp], str):\n",
    "            a = np.multiply([data[c] == data[c][lp]],1)\n",
    "            data.drop(c, 1, inplace=True)\n",
    "            data[c] = a[0]\n",
    "        data[c] = np.nan_to_num(data[c], copy=True, nan=data[c].median())\n",
    "    \n",
    "    # Correlation matrix of the data columns \n",
    "    corr_matrix = data.corr().abs()\n",
    "    high_corr_var=np.where(corr_matrix>0.75)\n",
    "    high_corr_var=np.array([(corr_matrix.columns[x],corr_matrix.columns[y]) for x,y in zip(*high_corr_var) if x!=y and x<y])\n",
    "    \n",
    "    # Suppresion of correlate columns\n",
    "    for i in range(len(high_corr_var)):\n",
    "        c = high_corr_var[i][0]\n",
    "        data.drop(c, 1, inplace=True)\n",
    "        \n",
    "    X = data\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Creation of a dataset to train and another to test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "    return  x_train, x_test, y_train, y_test, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data_set1\n",
    "x_train1, x_test1, y_train1, y_test1, X1, Y1 = preprocessing(\"data_banknote_authentication.csv\", \"class\", 4, \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data_set2\n",
    "x_train2, x_test2, y_train2, y_test2, X2, Y2 = preprocessing(\"kidney_disease.csv\", \"classification\", 4, ',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# the function that give the percentage of accuracy of the function (the same as .score())\n",
    "def accuracy(y_predict, y_test):\n",
    "    return np.mean([y_predict==y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Models import list\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# model could take the value \"best\" or \"scores\"\n",
    "def models_1cv(x_train, x_test, y_train, y_test, model): \n",
    "    # Models list\n",
    "    models = [svm.SVC(kernel='linear'),\n",
    "              svm.SVC(kernel='poly', degree=2, gamma='auto'),\n",
    "              svm.SVC(kernel='rbf', gamma='auto'),\n",
    "              svm.SVC(kernel='sigmoid', gamma=1./150),\n",
    "              SGDClassifier(),\n",
    "              DecisionTreeClassifier(),\n",
    "              GaussianNB(),\n",
    "              RandomForestRegressor(n_estimators = 1000, random_state = 42),\n",
    "              MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=42),\n",
    "              LogisticRegression(random_state=0)]\n",
    "    # Models apply the train dataset list\n",
    "    models = [clf.fit(x_train, y_train) for clf in models]\n",
    "    # Models score list\n",
    "    scores = [clf.score(x_test,y_test) for clf in models]\n",
    "\n",
    "    # Models name list \n",
    "    titles = ['SVC with linear kernel',\n",
    "              'SVC with polynomial (degree 2) kernel',\n",
    "              'SVC with RBF kernel',\n",
    "              'SVC with sigmoid kernel',\n",
    "              'Stochastic Gradient Descent',\n",
    "              'Desicion Trees',\n",
    "              'Bayesien Network: Gnb',\n",
    "              'Random Forest',\n",
    "              'Neural Network',\n",
    "              'Probit model']\n",
    "    \n",
    "    if model == 'best':\n",
    "        # return the name and the score of the method that obtain the best result \n",
    "        return titles[scores.index(max(scores))], max(scores)\n",
    "    if model == 'scores':\n",
    "        # return the name and the score of all the method\n",
    "        return [(titles[i],scores[i]) for i in range(10)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SVC with RBF kernel', 0.9709090909090909)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_1cv(x_train1, x_test1, y_train1, y_test1, 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SVC with RBF kernel', 0.9875)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_1cv(x_train2, x_test2, y_train2, y_test2, 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SVC with linear kernel', 0.9090909090909091),\n",
       " ('SVC with polynomial (degree 2) kernel', 0.7236363636363636),\n",
       " ('SVC with RBF kernel', 0.9709090909090909),\n",
       " ('SVC with sigmoid kernel', 0.8909090909090909),\n",
       " ('Stochastic Gradient Descent', 0.8872727272727273),\n",
       " ('Desicion Trees', 0.9563636363636364),\n",
       " ('Bayesien Network: Gnb', 0.8036363636363636),\n",
       " ('Random Forest', 0.9055074922855927),\n",
       " ('Neural Network', 0.9672727272727273),\n",
       " ('Probit model', 0.9054545454545454)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_1cv(x_train1, x_test1, y_train1, y_test1, 'scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models import list\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# model could take the value \"best\" or \"scores\"\n",
    "def models_Ncv(X, Y, N, model):\n",
    "    # Models list\n",
    "    models = [svm.SVC(kernel='linear'),\n",
    "              svm.SVC(kernel='poly', degree=2, gamma='auto'),\n",
    "              svm.SVC(kernel='rbf', gamma='auto'),\n",
    "              svm.SVC(kernel='sigmoid', gamma=1./150),\n",
    "              SGDClassifier(),\n",
    "              DecisionTreeClassifier(),\n",
    "              GaussianNB(),\n",
    "              RandomForestRegressor(n_estimators = 1000, random_state = 42),\n",
    "              MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=42),\n",
    "              LogisticRegression(random_state=0)]\n",
    "    # Models score list with a N-cross-validation (the method is try N times each)\n",
    "    scores = [np.mean(cross_val_score(clf, X, Y, cv=N)) for clf in models]\n",
    "    \n",
    "    # Models name list\n",
    "    titles = ['SVC with linear kernel',\n",
    "              'SVC with polynomial (degree 2) kernel',\n",
    "              'SVC with RBF kernel',\n",
    "              'SVC with sigmoid kernel',\n",
    "              'Stochastic Gradient Descent',\n",
    "              'Desicion Trees',\n",
    "              'Bayesien Network: Gnb',\n",
    "              'Random Forest',\n",
    "              'Neural Network',\n",
    "              'Probit model']\n",
    "    \n",
    "    if model == 'best':\n",
    "        # return the name and the score of the method that obtain the best result \n",
    "        return titles[scores.index(max(scores))], max(scores)\n",
    "    if model == 'scores':\n",
    "        # return the name and the score of all the method\n",
    "        return [(titles[i],scores[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SVC with RBF kernel', 0.9832487041150959)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_Ncv(X1,Y1,10, 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SVC with RBF kernel', 0.9875)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_Ncv(X2,Y2,10, 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SVC with linear kernel', 0.9082196128213266),\n",
       " ('SVC with polynomial (degree 2) kernel', 0.7377975245953665),\n",
       " ('SVC with RBF kernel', 0.9832487041150959),\n",
       " ('SVC with sigmoid kernel', 0.8965672273352375),\n",
       " ('Stochastic Gradient Descent', 0.8936898339151593),\n",
       " ('Desicion Trees', 0.9628530625198349),\n",
       " ('Bayesien Network: Gnb', 0.8325187771077964),\n",
       " ('Random Forest', 0.0922050889032258),\n",
       " ('Neural Network', 0.9766952290278219),\n",
       " ('Probit model', 0.9067703374590078)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_Ncv(X1,Y1,10, 'scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models import list\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def model_mean(x_train, x_test, y_train, y_test, model):\n",
    "    # Models list\n",
    "    models = [svm.SVC(kernel='linear'),\n",
    "              svm.SVC(kernel='poly', degree=2, gamma='auto'),\n",
    "              svm.SVC(kernel='rbf', gamma='auto'),\n",
    "              svm.SVC(kernel='sigmoid', gamma=1./150),\n",
    "              SGDClassifier(),\n",
    "              DecisionTreeClassifier(),\n",
    "              GaussianNB(),\n",
    "              RandomForestRegressor(n_estimators = 1000, random_state = 42),\n",
    "              MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=42),\n",
    "              LogisticRegression(random_state=0)]\n",
    "    # Models apply the train dataset list\n",
    "    models = [clf.fit(x_train, y_train) for clf in models]\n",
    "    # Models predictions for the input x_test\n",
    "    predicts = [clf.predict(x_test) for clf in models]\n",
    "    # Models score list\n",
    "    scores = [clf.score(x_test,y_test) for clf in models]\n",
    "    # Models predictions mean \n",
    "    mean_predict = sum(p for p in predicts)/10\n",
    "    mean_predict = [np.round(mean_predict[i]) for i in range(len(mean_predict))]\n",
    "    # Add model mean score to scores\n",
    "    scores.append(accuracy(mean_predict, y_test))\n",
    "\n",
    "    # Models name list\n",
    "    titles = ['SVC with linear kernel',\n",
    "              'SVC with polynomial (degree 2) kernel',\n",
    "              'SVC with RBF kernel',\n",
    "              'SVC with sigmoid kernel',\n",
    "              'Stochastic Gradient Descent',\n",
    "              'Desicion Trees',\n",
    "              'Bayesien Network: Gnb',\n",
    "              'Random Forest',\n",
    "              'Neural Network',\n",
    "              'Probit model',\n",
    "              'Model Mean']\n",
    "\n",
    "    if model == 'best':\n",
    "        # return the name and the score of the method that obtain the best result \n",
    "        return titles[scores.index(max(scores))], max(scores)\n",
    "    if model == 'scores':\n",
    "        # return the name and the score of all the method\n",
    "        return [(titles[i],scores[i]) for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SVC with RBF kernel', 0.9709090909090909)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mean(x_train1, x_test1, y_train1, y_test1, 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Model Mean', 1.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mean(x_train2, x_test2, y_train2, y_test2, 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SVC with linear kernel', 0.9090909090909091),\n",
       " ('SVC with polynomial (degree 2) kernel', 0.7236363636363636),\n",
       " ('SVC with RBF kernel', 0.9709090909090909),\n",
       " ('SVC with sigmoid kernel', 0.8909090909090909),\n",
       " ('Stochastic Gradient Descent', 0.8945454545454545),\n",
       " ('Desicion Trees', 0.9527272727272728),\n",
       " ('Bayesien Network: Gnb', 0.8036363636363636),\n",
       " ('Random Forest', 0.9055074922855927),\n",
       " ('Neural Network', 0.9672727272727273),\n",
       " ('Probit model', 0.9054545454545454),\n",
       " ('Model Mean', 0.9345454545454546)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mean(x_train1, x_test1, y_train1, y_test1, 'scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBAL FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries: Standard ones\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rnd\n",
    "# Libraries: scikit learn for preprocessing \n",
    "from sklearn.preprocessing import StandardScalefrom sklearn.model_selection import train_test_split\n",
    "# Models import list\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def finalFunction(abcd_csv, clas, lp, sep, N, model):\n",
    "    # Data cleaning \n",
    "    x_train, x_test, y_train, y_test, X, Y = preprocessing(abcd_csv, clas, lp, sep)\n",
    "    # Show the result \n",
    "    if N == 1:\n",
    "        return model_mean(x_train, x_test, y_train, y_test, model)\n",
    "    if N > 1:\n",
    "        return models_Ncv(X, Y, N, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
