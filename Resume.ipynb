{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(abcd_csv, clas, lp):\n",
    "    \n",
    "    # Libraries: Standard ones\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random as rnd\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Load the data: data_banknote_authentification\n",
    "    data = pd.read_csv(abcd_csv,sep=\";\")\n",
    "    # Statistical summary of the data\n",
    "    data.describe() \n",
    "    \n",
    "    # X/Y separation\n",
    "    if isinstance(data[clas][0], str):\n",
    "        Y = np.multiply([data[clas]==data[clas][0]],1)[0]\n",
    "    else:\n",
    "        Y = data[clas]\n",
    "    data.drop(clas, 1, inplace=True)\n",
    "    for c in data:\n",
    "        if isinstance(data[c][lp], str):\n",
    "            a = np.multiply([data[c] == data[c][lp]],1)\n",
    "            data.drop(c, 1, inplace=True)\n",
    "            data[c] = a[0]\n",
    "        data[c] = np.nan_to_num(data[c], copy=True, nan=data[c].median())\n",
    "    \n",
    "    # Correlate columns \n",
    "    corr_matrix = data.corr().abs()\n",
    "    high_corr_var=np.where(corr_matrix>0.75)\n",
    "    high_corr_var=np.array([(corr_matrix.columns[x],corr_matrix.columns[y]) for x,y in zip(*high_corr_var) if x!=y and x<y])\n",
    "    drop_corr = []\n",
    "    for i in range(len(high_corr_var)):\n",
    "        if high_corr_var[i][0] not in drop_corr and high_corr_var[i][1] not in drop_corr:\n",
    "            c = high_corr_var[i][0]\n",
    "            drop_corr.append(c)\n",
    "            data.drop(c, 1, inplace=True)\n",
    "        elif high_corr_var[i][0] in drop_corr:\n",
    "            c = high_corr_var[i][1]\n",
    "            drop_corr.append(c)\n",
    "            data.drop(c, 1, inplace=True)\n",
    "        elif high_corr_var[i][1] in drop_corr:\n",
    "            c = high_corr_var[i][0]\n",
    "            drop_corr.append(c)\n",
    "            data.drop(c, 1, inplace=True)\n",
    "    X = data\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    #\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "    return  x_train, x_test, y_train, y_test, X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def accuracy(y_predict, y_test):\n",
    "    return np.mean([y_predict==y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# liste des models \n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def models_1cv(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    models = [svm.SVC(kernel='linear'),\n",
    "              svm.SVC(kernel='poly', degree=2, gamma='auto'),\n",
    "              svm.SVC(kernel='rbf', gamma='auto'),\n",
    "              svm.SVC(kernel='sigmoid', gamma=1./150),\n",
    "              SGDClassifier(),\n",
    "              DecisionTreeClassifier(),\n",
    "              GaussianNB(),\n",
    "              RandomForestRegressor(n_estimators = 1000, random_state = 42),\n",
    "              MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=42),\n",
    "              LogisticRegression(random_state=0)]\n",
    "\n",
    "    models = [clf.fit(x_train, y_train) for clf in models]\n",
    "\n",
    "    scores = [clf.score(x_test,y_test) for clf in models]\n",
    "\n",
    "    # title \n",
    "    titles = ['SVC with linear kernel',\n",
    "              'SVC with polynomial (degree 2) kernel',\n",
    "              'SVC with RBF kernel',\n",
    "              'SVC with sigmoid kernel',\n",
    "              'Stochastic Gradient Descent',\n",
    "              'Desicion Trees',\n",
    "              'Bayesien Network: Gnb',\n",
    "              'Random Forest',\n",
    "              'Neural Network',\n",
    "              'Probit model']\n",
    "\n",
    "    return titles[scores.index(max(scores))], max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data_set1\n",
    "x_train, x_test, y_train, y_test, X, Y = preprocessing(\"data_banknote_authentification.csv\", \"classification\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'classification'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\envs\\LAB_3.7\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2888\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2889\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'classification'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-7c785c6172b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"kidney_disease.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"classification\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodels_1cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-4899d011ad0a>\u001b[0m in \u001b[0;36mpreprocessing\u001b[1;34m(abcd_csv, clas, lp)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# X/Y separation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclas\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclas\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclas\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\LAB_3.7\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\LAB_3.7\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'classification'"
     ]
    }
   ],
   "source": [
    "#test data_set2\n",
    "x_train, x_test, y_train, y_test, X, Y = preprocessing(\"kidney_disease.csv\", \"classification\", 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste des models \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def models_Ncv(X, Y, N):\n",
    "    \n",
    "    models = [svm.SVC(kernel='linear'),\n",
    "              svm.SVC(kernel='poly', degree=2, gamma='auto'),\n",
    "              svm.SVC(kernel='rbf', gamma='auto'),\n",
    "              svm.SVC(kernel='sigmoid', gamma=1./150),\n",
    "              SGDClassifier(),\n",
    "              DecisionTreeClassifier(),\n",
    "              GaussianNB(),\n",
    "              RandomForestRegressor(n_estimators = 1000, random_state = 42),\n",
    "              MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=42),\n",
    "              LogisticRegression(random_state=0)]\n",
    "    \n",
    "    scores = [np.mean(cross_val_score(clf, X, Y, cv=N)) for clf in models]\n",
    "    \n",
    "    # title \n",
    "    titles = ['SVC with linear kernel',\n",
    "              'SVC with polynomial (degree 2) kernel',\n",
    "              'SVC with RBF kernel',\n",
    "              'SVC with sigmoid kernel',\n",
    "              'Stochastic Gradient Descent',\n",
    "              'Desicion Trees',\n",
    "              'Bayesien Network: Gnb',\n",
    "              'Random Forest',\n",
    "              'Neural Network',\n",
    "              'Probit model']\n",
    "    \n",
    "    return titles[scores.index(max(scores))], max(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SVC with RBF kernel', 0.9781521466977309)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_Ncv(X,Y,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste des models \n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def model_mean(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    models = [svm.SVC(kernel='linear'),\n",
    "              svm.SVC(kernel='poly', degree=2, gamma='auto'),\n",
    "              svm.SVC(kernel='rbf', gamma='auto'),\n",
    "              svm.SVC(kernel='sigmoid', gamma=1./150),\n",
    "              SGDClassifier(),\n",
    "              DecisionTreeClassifier(),\n",
    "              GaussianNB(),\n",
    "              RandomForestRegressor(n_estimators = 1000, random_state = 42),\n",
    "              MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=42),\n",
    "              LogisticRegression(random_state=0)]\n",
    "\n",
    "    models = [clf.fit(x_train, y_train) for clf in models]\n",
    "    \n",
    "    predicts = [clf.predict(x_test) for clf in models]\n",
    "\n",
    "    scores = [clf.score(x_test,y_test) for clf in models]\n",
    "    \n",
    "    mean_predict = sum(p for p in predicts)/10\n",
    "    mean_predict = [np.round(mean_predict[i]) for i in range(len(mean_predict))]\n",
    "    \n",
    "    scores.append(accuracy(mean_predict, y_test))\n",
    "\n",
    "    # title \n",
    "    titles = ['SVC with linear kernel',\n",
    "              'SVC with polynomial (degree 2) kernel',\n",
    "              'SVC with RBF kernel',\n",
    "              'SVC with sigmoid kernel',\n",
    "              'Stochastic Gradient Descent',\n",
    "              'Desicion Trees',\n",
    "              'Bayesien Network: Gnb',\n",
    "              'Random Forest',\n",
    "              'Neural Network',\n",
    "              'Probit model',\n",
    "              'Model Mean']\n",
    "\n",
    "    return titles[scores.index(max(scores))], max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529     0\n",
      "243     0\n",
      "1310    1\n",
      "664     0\n",
      "745     0\n",
      "       ..\n",
      "1095    1\n",
      "1130    1\n",
      "1294    1\n",
      "860     1\n",
      "1126    1\n",
      "Name: class, Length: 1098, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('SVC with RBF kernel', 0.9709090909090909)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mean(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
